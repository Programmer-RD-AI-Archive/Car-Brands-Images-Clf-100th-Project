{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop((112)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_size=112):\n",
    "    data = []\n",
    "    labels = {}\n",
    "    index = -1\n",
    "    for label in os.listdir('./data/'):\n",
    "        index += 1\n",
    "        labels[label] = index\n",
    "    print(len(labels))\n",
    "    X = []\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        for file in os.listdir(f'./data/{label}/'):\n",
    "            path = f'./data/{label}/{file}'\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            data.append([np.array(transform_data(np.array(img))),labels[label]])\n",
    "            X.append(np.array(transform_data(np.array(img))))\n",
    "            y.append(labels[label])\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.save('./data.npy',data)\n",
    "    print(int(len(data)/7))\n",
    "    data = data[:int(len(data)/7)]\n",
    "    X = X[:int(len(data)/7)]\n",
    "    y = y[:int(len(data)/7)]\n",
    "    VAL_SPLIT = 0.25\n",
    "    VAL_SPLIT = len(X)*VAL_SPLIT\n",
    "    VAL_SPLIT = int(VAL_SPLIT)\n",
    "    X_train = X[:-VAL_SPLIT]\n",
    "    y_train = y[:-VAL_SPLIT]\n",
    "    X_test = X[-VAL_SPLIT:]\n",
    "    y_test = y[-VAL_SPLIT:]\n",
    "    X = torch.from_numpy(np.array(X))\n",
    "    y = torch.from_numpy(np.array(y))\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    return X,y,X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n"
     ]
    }
   ],
   "source": [
    "X,y,X_train,X_test,y_train,y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,5)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.conv2batchnorm = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        self.fc1 = nn.Linear(128*10*10,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,50)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = F.max_pool2d(self.relu(self.conv1(X)),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv2batchnorm(self.conv2(preds))),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv3(preds)),(2,2))\n",
    "        preds = preds.view(-1,128*10*10)\n",
    "        preds = self.relu(self.fc1(preds))\n",
    "        preds = self.relu(self.fc2(preds))\n",
    "        preds = self.relu(self.fc3(preds))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BaseLine().to(device)\n",
    "# model = model.to(device)\n",
    "\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "in_f = model.fc.in_features\n",
    "model.fc = nn.Linear(in_f,50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Car-Brands-Images-Clf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=PROJECT_NAME,name='transfer-learning')\n",
    "# for _ in tqdm(range(EPOCHS)):\n",
    "#     for i in range(0,len(X_train),BATCH_SIZE):\n",
    "#         X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "#         y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "#         model.to(device)\n",
    "#         preds = model(X_batch)\n",
    "#         preds = preds.to(device)\n",
    "#         loss = criterion(preds,y_batch)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         wandb.log({'loss':loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL vs Custom Model best = TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(criterion,y,model,X):\n",
    "    model.to('cuda')\n",
    "    preds = model(X.view(-1,3,112,112).to('cuda').float())\n",
    "    preds.to('cuda')\n",
    "    loss = criterion(preds,torch.tensor(y,dtype=torch.long).to('cuda'))\n",
    "    loss.backward()\n",
    "    return loss.item()\n",
    "def test(net,X,y):\n",
    "    device = 'cuda'\n",
    "    net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            real_class = torch.argmax(y[i]).to(device)\n",
    "            net_out = net(X[i].view(-1,3,112,112).to(device).float())\n",
    "            net_out = net_out[0]\n",
    "            predictied_class = torch.argmax(net_out)\n",
    "            if predictied_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    net.train()\n",
    "    net.to('cuda')\n",
    "    return round(correct/total,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.shufflenet_v2_x1_0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3f1em4rw\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3f1em4rw</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_100812-3f1em4rw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      "  1%|          | 1/108 [00:24<43:07, 24.18s/it]\u001b[A\n",
      "  2%|▏         | 2/108 [00:48<42:38, 24.14s/it]\u001b[A\n",
      "  3%|▎         | 3/108 [01:12<42:12, 24.12s/it]\u001b[A\n",
      "  4%|▎         | 4/108 [01:36<41:44, 24.08s/it]\u001b[A\n",
      "  5%|▍         | 5/108 [02:00<41:20, 24.08s/it]\u001b[A\n",
      "  6%|▌         | 6/108 [02:24<40:56, 24.09s/it]\u001b[A\n",
      "  6%|▋         | 7/108 [02:48<40:30, 24.07s/it]\u001b[A\n",
      "  7%|▋         | 8/108 [03:12<40:05, 24.06s/it]\u001b[A\n",
      "  8%|▊         | 9/108 [03:36<39:37, 24.02s/it]\u001b[A\n",
      "  9%|▉         | 10/108 [04:00<39:12, 24.01s/it]\u001b[A\n",
      " 10%|█         | 11/108 [04:24<38:56, 24.08s/it]\u001b[A\n",
      " 11%|█         | 12/108 [04:49<38:41, 24.18s/it]\u001b[A\n",
      " 12%|█▏        | 13/108 [05:13<38:13, 24.14s/it]\u001b[A\n",
      " 13%|█▎        | 14/108 [05:37<37:45, 24.10s/it]\u001b[A\n",
      " 14%|█▍        | 15/108 [06:01<37:17, 24.06s/it]\u001b[A\n",
      " 15%|█▍        | 16/108 [06:25<36:51, 24.04s/it]\u001b[A\n",
      " 16%|█▌        | 17/108 [06:49<36:23, 23.99s/it]\u001b[A\n",
      " 17%|█▋        | 18/108 [07:13<36:00, 24.01s/it]\u001b[A\n",
      " 18%|█▊        | 19/108 [07:37<35:37, 24.02s/it]\u001b[A\n",
      " 19%|█▊        | 20/108 [08:01<35:11, 24.00s/it]\u001b[A\n",
      " 19%|█▉        | 21/108 [08:25<34:48, 24.01s/it]\u001b[A\n",
      " 20%|██        | 22/108 [08:49<34:26, 24.03s/it]\u001b[A\n",
      " 21%|██▏       | 23/108 [09:13<34:00, 24.00s/it]\u001b[A\n",
      " 22%|██▏       | 24/108 [09:37<33:36, 24.01s/it]\u001b[A\n",
      " 23%|██▎       | 25/108 [10:01<33:12, 24.01s/it]\u001b[A\n",
      " 24%|██▍       | 26/108 [10:25<32:47, 23.99s/it]\u001b[A\n",
      " 25%|██▌       | 27/108 [10:49<32:26, 24.03s/it]\u001b[A\n",
      " 26%|██▌       | 28/108 [11:13<32:01, 24.02s/it]\u001b[A\n",
      " 27%|██▋       | 29/108 [11:37<31:36, 24.01s/it]\u001b[A\n",
      " 28%|██▊       | 30/108 [12:01<31:15, 24.04s/it]\u001b[A\n",
      " 29%|██▊       | 31/108 [12:25<30:48, 24.01s/it]\u001b[A\n",
      " 30%|██▉       | 32/108 [12:49<30:24, 24.01s/it]\u001b[A\n",
      " 31%|███       | 33/108 [13:13<30:00, 24.01s/it]\u001b[A\n",
      " 31%|███▏      | 34/108 [13:37<29:37, 24.01s/it]\u001b[A\n",
      " 32%|███▏      | 35/108 [14:01<29:14, 24.03s/it]\u001b[A\n",
      " 33%|███▎      | 36/108 [14:25<28:51, 24.04s/it]\u001b[A\n",
      " 34%|███▍      | 37/108 [14:49<28:25, 24.01s/it]\u001b[A\n",
      " 35%|███▌      | 38/108 [15:13<28:01, 24.02s/it]\u001b[A\n",
      " 36%|███▌      | 39/108 [15:37<27:36, 24.01s/it]\u001b[A\n",
      " 37%|███▋      | 40/108 [16:01<27:11, 24.00s/it]\u001b[A\n",
      " 38%|███▊      | 41/108 [16:25<26:49, 24.02s/it]\u001b[A\n",
      " 39%|███▉      | 42/108 [16:49<26:25, 24.02s/it]\u001b[A\n",
      " 40%|███▉      | 43/108 [17:13<26:02, 24.04s/it]\u001b[A\n",
      " 41%|████      | 44/108 [17:37<25:37, 24.02s/it]\u001b[A\n",
      " 42%|████▏     | 45/108 [18:02<25:24, 24.20s/it]\u001b[A\n",
      " 43%|████▎     | 46/108 [18:26<24:59, 24.18s/it]\u001b[A\n",
      " 44%|████▎     | 47/108 [18:50<24:31, 24.13s/it]\u001b[A\n",
      " 44%|████▍     | 48/108 [19:14<24:05, 24.09s/it]\u001b[A\n",
      " 45%|████▌     | 49/108 [19:38<23:41, 24.10s/it]\u001b[A\n",
      " 46%|████▋     | 50/108 [20:02<23:16, 24.07s/it]\u001b[A\n",
      " 47%|████▋     | 51/108 [20:26<22:49, 24.02s/it]\u001b[A\n",
      " 48%|████▊     | 52/108 [20:50<22:24, 24.01s/it]\u001b[A\n",
      " 49%|████▉     | 53/108 [21:14<21:59, 23.99s/it]\u001b[A\n",
      " 50%|█████     | 54/108 [21:38<21:33, 23.95s/it]\u001b[A\n",
      " 51%|█████     | 55/108 [22:02<21:10, 23.97s/it]\u001b[A\n",
      " 52%|█████▏    | 56/108 [22:26<20:49, 24.03s/it]\u001b[A\n",
      " 53%|█████▎    | 57/108 [22:50<20:25, 24.03s/it]\u001b[A\n",
      " 54%|█████▎    | 58/108 [23:14<20:03, 24.06s/it]\u001b[A\n",
      " 55%|█████▍    | 59/108 [23:38<19:38, 24.06s/it]\u001b[A\n",
      " 56%|█████▌    | 60/108 [24:02<19:14, 24.06s/it]\u001b[A\n",
      " 56%|█████▋    | 61/108 [24:26<18:50, 24.06s/it]\u001b[A\n",
      " 57%|█████▋    | 62/108 [24:50<18:26, 24.05s/it]\u001b[A\n",
      " 58%|█████▊    | 63/108 [25:14<18:02, 24.05s/it]\u001b[A\n",
      " 59%|█████▉    | 64/108 [25:38<17:37, 24.03s/it]\u001b[A\n",
      " 60%|██████    | 65/108 [26:02<17:13, 24.04s/it]\u001b[A\n",
      " 61%|██████    | 66/108 [26:26<16:48, 24.01s/it]\u001b[A\n",
      " 62%|██████▏   | 67/108 [26:50<16:23, 23.99s/it]\u001b[A\n",
      " 63%|██████▎   | 68/108 [27:14<16:00, 24.00s/it]\u001b[A\n",
      " 64%|██████▍   | 69/108 [27:38<15:37, 24.04s/it]\u001b[A\n",
      " 65%|██████▍   | 70/108 [28:02<15:12, 24.01s/it]\u001b[A\n",
      " 66%|██████▌   | 71/108 [28:26<14:47, 23.99s/it]\u001b[A\n",
      " 67%|██████▋   | 72/108 [28:50<14:22, 23.97s/it]\u001b[A\n",
      " 68%|██████▊   | 73/108 [29:14<13:59, 23.99s/it]\u001b[A\n",
      " 69%|██████▊   | 74/108 [29:38<13:36, 24.00s/it]\u001b[A\n",
      " 69%|██████▉   | 75/108 [30:02<13:13, 24.06s/it]\u001b[A\n",
      " 70%|███████   | 76/108 [30:26<12:49, 24.05s/it]\u001b[A\n",
      " 71%|███████▏  | 77/108 [30:50<12:24, 24.03s/it]\u001b[A\n",
      " 72%|███████▏  | 78/108 [31:14<12:00, 24.02s/it]\u001b[A\n",
      " 73%|███████▎  | 79/108 [31:39<11:37, 24.05s/it]\u001b[A\n",
      " 74%|███████▍  | 80/108 [32:03<11:13, 24.04s/it]\u001b[A\n",
      " 75%|███████▌  | 81/108 [32:27<10:48, 24.02s/it]\u001b[A\n",
      " 76%|███████▌  | 82/108 [32:51<10:24, 24.02s/it]\u001b[A\n",
      " 77%|███████▋  | 83/108 [33:15<10:00, 24.00s/it]\u001b[A\n",
      " 78%|███████▊  | 84/108 [33:39<09:36, 24.00s/it]\u001b[A\n",
      " 79%|███████▊  | 85/108 [34:03<09:11, 24.00s/it]\u001b[A\n",
      " 80%|███████▉  | 86/108 [34:27<08:48, 24.03s/it]\u001b[A\n",
      " 81%|████████  | 87/108 [34:51<08:24, 24.02s/it]\u001b[A\n",
      " 81%|████████▏ | 88/108 [35:15<08:00, 24.00s/it]\u001b[A\n",
      " 82%|████████▏ | 89/108 [35:39<07:36, 24.00s/it]\u001b[A\n",
      " 83%|████████▎ | 90/108 [36:03<07:12, 24.03s/it]\u001b[A\n",
      " 84%|████████▍ | 91/108 [36:27<06:48, 24.02s/it]\u001b[A\n",
      " 85%|████████▌ | 92/108 [36:51<06:23, 23.99s/it]\u001b[A\n",
      " 86%|████████▌ | 93/108 [37:15<05:59, 23.99s/it]\u001b[A\n",
      " 87%|████████▋ | 94/108 [37:39<05:35, 24.00s/it]\u001b[A\n",
      " 88%|████████▊ | 95/108 [38:03<05:11, 23.99s/it]\u001b[A\n",
      " 89%|████████▉ | 96/108 [38:27<04:48, 24.03s/it]\u001b[A\n",
      " 90%|████████▉ | 97/108 [38:51<04:24, 24.01s/it]\u001b[A\n",
      " 91%|█████████ | 98/108 [39:15<04:00, 24.02s/it]\u001b[A\n",
      " 92%|█████████▏| 99/108 [39:39<03:35, 23.99s/it]\u001b[A\n",
      " 93%|█████████▎| 100/108 [40:03<03:12, 24.01s/it]\u001b[A\n",
      " 94%|█████████▎| 101/108 [40:27<02:48, 24.02s/it]\u001b[A\n",
      " 94%|█████████▍| 102/108 [40:51<02:24, 24.05s/it]\u001b[A\n",
      " 95%|█████████▌| 103/108 [41:15<02:00, 24.01s/it]\u001b[A\n",
      " 96%|█████████▋| 104/108 [41:39<01:36, 24.00s/it]\u001b[A\n",
      " 97%|█████████▋| 105/108 [42:03<01:12, 24.03s/it]\u001b[A\n",
      " 98%|█████████▊| 106/108 [42:27<00:48, 24.02s/it]\u001b[A\n",
      " 99%|█████████▉| 107/108 [42:51<00:24, 24.00s/it]\u001b[A\n",
      "100%|██████████| 108/108 [43:15<00:00, 24.00s/it]\u001b[A\n",
      "  8%|▊         | 1/12 [43:15<7:55:48, 2595.35s/it]\n",
      "  0%|          | 0/108 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/108 [00:24<42:48, 24.01s/it]\u001b[A\n",
      "  2%|▏         | 2/108 [00:48<42:24, 24.01s/it]\u001b[A\n",
      "  3%|▎         | 3/108 [01:11<41:58, 23.99s/it]\u001b[A\n",
      "  4%|▎         | 4/108 [01:35<41:34, 23.99s/it]\u001b[A\n",
      "  5%|▍         | 5/108 [01:59<41:12, 24.00s/it]\u001b[A\n",
      "  6%|▌         | 6/108 [02:24<40:50, 24.02s/it]\u001b[A\n",
      "  6%|▋         | 7/108 [02:48<40:24, 24.00s/it]\u001b[A\n",
      "  7%|▋         | 8/108 [03:11<39:56, 23.97s/it]\u001b[A\n",
      "  8%|▊         | 9/108 [03:35<39:32, 23.96s/it]\u001b[A\n",
      "  9%|▉         | 10/108 [03:59<39:08, 23.96s/it]\u001b[A\n",
      " 10%|█         | 11/108 [04:23<38:45, 23.98s/it]\u001b[A\n",
      " 11%|█         | 12/108 [04:47<38:21, 23.97s/it]\u001b[A\n",
      " 12%|█▏        | 13/108 [05:11<37:54, 23.94s/it]\u001b[A\n",
      " 13%|█▎        | 14/108 [05:35<37:29, 23.93s/it]\u001b[A\n",
      " 14%|█▍        | 15/108 [05:59<37:05, 23.93s/it]\u001b[A\n",
      " 15%|█▍        | 16/108 [06:23<36:43, 23.95s/it]\u001b[A\n",
      " 16%|█▌        | 17/108 [06:47<36:18, 23.93s/it]\u001b[A\n",
      " 17%|█▋        | 18/108 [07:11<35:53, 23.93s/it]\u001b[A\n",
      " 18%|█▊        | 19/108 [07:35<35:29, 23.92s/it]\u001b[A\n",
      " 19%|█▊        | 20/108 [07:59<35:05, 23.93s/it]\u001b[A\n",
      " 19%|█▉        | 21/108 [08:23<34:40, 23.91s/it]\u001b[A\n",
      " 20%|██        | 22/108 [08:46<34:17, 23.93s/it]\u001b[A\n",
      " 21%|██▏       | 23/108 [09:10<33:53, 23.92s/it]\u001b[A\n",
      " 22%|██▏       | 24/108 [09:34<33:30, 23.94s/it]\u001b[A\n",
      " 23%|██▎       | 25/108 [09:58<33:06, 23.94s/it]\u001b[A\n",
      " 24%|██▍       | 26/108 [10:22<32:44, 23.96s/it]\u001b[A\n",
      " 25%|██▌       | 27/108 [10:46<32:21, 23.97s/it]\u001b[A\n",
      " 26%|██▌       | 28/108 [11:10<31:57, 23.97s/it]\u001b[A\n",
      " 27%|██▋       | 29/108 [11:34<31:32, 23.96s/it]\u001b[A\n",
      " 28%|██▊       | 30/108 [11:58<31:11, 24.00s/it]\u001b[A\n",
      " 29%|██▊       | 31/108 [12:22<30:44, 23.95s/it]\u001b[A\n",
      " 30%|██▉       | 32/108 [12:46<30:19, 23.93s/it]\u001b[A\n",
      " 31%|███       | 33/108 [13:10<29:56, 23.95s/it]\u001b[A\n",
      " 31%|███▏      | 34/108 [13:34<29:32, 23.95s/it]\u001b[A\n",
      " 32%|███▏      | 35/108 [13:58<29:08, 23.95s/it]\u001b[A\n",
      " 33%|███▎      | 36/108 [14:22<28:48, 24.01s/it]\u001b[A\n",
      " 34%|███▍      | 37/108 [14:46<28:22, 23.98s/it]\u001b[A\n",
      " 35%|███▌      | 38/108 [15:10<27:58, 23.98s/it]\u001b[A\n",
      " 36%|███▌      | 39/108 [15:34<27:33, 23.96s/it]\u001b[A\n",
      " 37%|███▋      | 40/108 [15:58<27:10, 23.97s/it]\u001b[A\n",
      " 38%|███▊      | 41/108 [16:22<26:46, 23.98s/it]\u001b[A\n",
      " 39%|███▉      | 42/108 [16:46<26:22, 23.98s/it]\u001b[A\n",
      " 40%|███▉      | 43/108 [17:10<26:00, 24.00s/it]\u001b[A\n",
      " 41%|████      | 44/108 [17:34<25:35, 23.98s/it]\u001b[A\n",
      " 42%|████▏     | 45/108 [17:58<25:09, 23.96s/it]\u001b[A\n",
      " 43%|████▎     | 46/108 [18:22<24:47, 23.99s/it]\u001b[A\n",
      " 44%|████▎     | 47/108 [18:46<24:26, 24.04s/it]\u001b[A\n",
      " 44%|████▍     | 48/108 [19:10<24:02, 24.04s/it]\u001b[A\n",
      " 45%|████▌     | 49/108 [19:34<23:35, 23.99s/it]\u001b[A\n",
      " 46%|████▋     | 50/108 [19:58<23:09, 23.96s/it]\u001b[A\n",
      " 47%|████▋     | 51/108 [20:22<22:45, 23.96s/it]\u001b[A\n",
      " 48%|████▊     | 52/108 [20:46<22:21, 23.96s/it]\u001b[A\n",
      " 49%|████▉     | 53/108 [21:10<21:57, 23.96s/it]\u001b[A\n",
      " 50%|█████     | 54/108 [21:34<21:32, 23.94s/it]\u001b[A\n",
      " 51%|█████     | 55/108 [21:58<21:08, 23.94s/it]\u001b[A\n",
      " 52%|█████▏    | 56/108 [22:21<20:45, 23.94s/it]\u001b[A\n",
      " 53%|█████▎    | 57/108 [22:46<20:23, 24.00s/it]\u001b[A\n",
      " 54%|█████▎    | 58/108 [23:10<19:58, 23.97s/it]\u001b[A\n",
      " 55%|█████▍    | 59/108 [23:33<19:33, 23.96s/it]\u001b[A\n",
      " 56%|█████▌    | 60/108 [23:57<19:10, 23.96s/it]\u001b[A\n",
      " 56%|█████▋    | 61/108 [24:21<18:45, 23.94s/it]\u001b[A\n",
      " 57%|█████▋    | 62/108 [24:45<18:22, 23.96s/it]\u001b[A\n",
      " 58%|█████▊    | 63/108 [25:09<17:57, 23.94s/it]\u001b[A\n",
      " 59%|█████▉    | 64/108 [25:33<17:32, 23.91s/it]\u001b[A\n",
      " 60%|██████    | 65/108 [25:57<17:07, 23.90s/it]\u001b[A\n",
      " 61%|██████    | 66/108 [26:21<16:45, 23.95s/it]\u001b[A\n",
      " 62%|██████▏   | 67/108 [26:45<16:21, 23.95s/it]\u001b[A\n",
      " 63%|██████▎   | 68/108 [27:09<15:59, 24.00s/it]\u001b[A\n",
      " 64%|██████▍   | 69/108 [27:33<15:36, 24.01s/it]\u001b[A\n",
      " 65%|██████▍   | 70/108 [27:57<15:12, 24.01s/it]\u001b[A\n",
      " 66%|██████▌   | 71/108 [28:21<14:47, 23.98s/it]\u001b[A\n",
      " 67%|██████▋   | 72/108 [28:45<14:23, 24.00s/it]\u001b[A\n",
      " 68%|██████▊   | 73/108 [29:09<13:59, 24.00s/it]\u001b[A\n",
      " 69%|██████▊   | 74/108 [29:33<13:35, 23.99s/it]\u001b[A\n",
      " 69%|██████▉   | 75/108 [29:57<13:11, 23.97s/it]\u001b[A\n",
      " 70%|███████   | 76/108 [30:21<12:48, 24.00s/it]\u001b[A\n",
      " 71%|███████▏  | 77/108 [30:45<12:23, 23.97s/it]\u001b[A\n",
      " 72%|███████▏  | 78/108 [31:09<11:58, 23.95s/it]\u001b[A\n",
      " 73%|███████▎  | 79/108 [31:33<11:34, 23.94s/it]\u001b[A\n",
      " 74%|███████▍  | 80/108 [31:57<11:09, 23.92s/it]\u001b[A\n",
      " 75%|███████▌  | 81/108 [32:21<10:46, 23.94s/it]\u001b[A\n",
      " 76%|███████▌  | 82/108 [32:45<10:23, 23.98s/it]\u001b[A\n",
      " 77%|███████▋  | 83/108 [33:09<10:00, 24.01s/it]\u001b[A\n",
      " 78%|███████▊  | 84/108 [33:33<09:36, 24.02s/it]\u001b[A\n",
      " 79%|███████▊  | 85/108 [33:57<09:12, 24.02s/it]\u001b[A\n",
      " 80%|███████▉  | 86/108 [34:21<08:47, 24.00s/it]\u001b[A\n",
      " 81%|████████  | 87/108 [34:45<08:24, 24.01s/it]\u001b[A\n",
      " 81%|████████▏ | 88/108 [35:09<08:00, 24.01s/it]\u001b[A\n",
      " 82%|████████▏ | 89/108 [35:33<07:35, 24.00s/it]\u001b[A\n",
      " 83%|████████▎ | 90/108 [35:57<07:12, 24.00s/it]\u001b[A\n",
      " 84%|████████▍ | 91/108 [36:21<06:48, 24.03s/it]\u001b[A\n",
      " 85%|████████▌ | 92/108 [36:45<06:24, 24.04s/it]\u001b[A\n",
      " 86%|████████▌ | 93/108 [37:09<06:00, 24.05s/it]\u001b[A\n",
      " 87%|████████▋ | 94/108 [37:33<05:36, 24.03s/it]\u001b[A\n",
      " 88%|████████▊ | 95/108 [37:57<05:12, 24.05s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "model = models.shufflenet_v2_x1_0(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.shufflenet_v2_x1_0')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_large(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mobilenet_v3_large')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_small(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mobilenet_v3_small')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnext50_32x4d(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.resnext50_32x4d')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.wide_resnet50_2(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.wide_resnet50_2')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mnasnet1_0(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mnasnet1_0')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.resnet18')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
