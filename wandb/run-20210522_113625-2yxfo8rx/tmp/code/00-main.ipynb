{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop((112)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_size=112):\n",
    "    data = []\n",
    "    labels = {}\n",
    "    index = -1\n",
    "    for label in os.listdir('./data/'):\n",
    "        index += 1\n",
    "        labels[label] = index\n",
    "    print(len(labels))\n",
    "    X = []\n",
    "    y = []\n",
    "    for label in labels:\n",
    "        for file in os.listdir(f'./data/{label}/'):\n",
    "            path = f'./data/{label}/{file}'\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img,(img_size,img_size))\n",
    "            data.append([np.array(transform_data(np.array(img))),labels[label]])\n",
    "            X.append(np.array(transform_data(np.array(img))))\n",
    "            y.append(labels[label])\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "    np.save('./data.npy',data)\n",
    "    print(int(len(data)/7))\n",
    "    data = data[:int(len(data)/7)]\n",
    "    X = X[:int(len(data)/7)]\n",
    "    y = y[:int(len(data)/7)]\n",
    "    VAL_SPLIT = 0.25\n",
    "    VAL_SPLIT = len(X)*VAL_SPLIT\n",
    "    VAL_SPLIT = int(VAL_SPLIT)\n",
    "    X_train = X[:-VAL_SPLIT]\n",
    "    y_train = y[:-VAL_SPLIT]\n",
    "    X_test = X[-VAL_SPLIT:]\n",
    "    y_test = y[-VAL_SPLIT:]\n",
    "    X = torch.from_numpy(np.array(X))\n",
    "    y = torch.from_numpy(np.array(y))\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    X_train = torch.from_numpy(X_train)\n",
    "    X_test = torch.from_numpy(X_test)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    return X,y,X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n"
     ]
    }
   ],
   "source": [
    "X,y,X_train,X_test,y_train,y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLine(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,5)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.conv2batchnorm = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64,128,5)\n",
    "        self.fc1 = nn.Linear(128*10*10,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,50)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = F.max_pool2d(self.relu(self.conv1(X)),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv2batchnorm(self.conv2(preds))),(2,2))\n",
    "        preds = F.max_pool2d(self.relu(self.conv3(preds)),(2,2))\n",
    "        preds = preds.view(-1,128*10*10)\n",
    "        preds = self.relu(self.fc1(preds))\n",
    "        preds = self.relu(self.fc2(preds))\n",
    "        preds = self.relu(self.fc3(preds))\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BaseLine().to(device)\n",
    "# model = model.to(device)\n",
    "\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "in_f = model.fc.in_features\n",
    "model.fc = nn.Linear(in_f,50)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Car-Brands-Images-Clf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=PROJECT_NAME,name='transfer-learning')\n",
    "# for _ in tqdm(range(EPOCHS)):\n",
    "#     for i in range(0,len(X_train),BATCH_SIZE):\n",
    "#         X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "#         y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "#         model.to(device)\n",
    "#         preds = model(X_batch)\n",
    "#         preds = preds.to(device)\n",
    "#         loss = criterion(preds,y_batch)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         wandb.log({'loss':loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL vs Custom Model best = TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(criterion,y,model,X):\n",
    "    model.to('cuda')\n",
    "    preds = model(X.view(-1,3,112,112).to('cuda').float())\n",
    "    preds.to('cuda')\n",
    "    loss = criterion(preds,torch.tensor(y,dtype=torch.long).to('cuda'))\n",
    "    loss.backward()\n",
    "    return loss.item()\n",
    "def test(net,X,y):\n",
    "    device = 'cuda'\n",
    "    net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X)):\n",
    "            real_class = torch.argmax(y[i]).to(device)\n",
    "            net_out = net(X[i].view(-1,3,112,112).to(device).float())\n",
    "            net_out = net_out[0]\n",
    "            predictied_class = torch.argmax(net_out)\n",
    "            if predictied_class == real_class:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    net.train()\n",
    "    net.to('cuda')\n",
    "    return round(correct/total,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 12\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.shufflenet_v2_x1_0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1oe1jdze\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1oe1jdze</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113237-1oe1jdze</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.10it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.46it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:01<00:21,  1.99s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.87it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:03<00:17,  1.76s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.83it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:05<00:15,  1.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.88it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:06<00:13,  1.68s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.33it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.58it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.70it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:08<00:12,  1.74s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.83it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:10<00:10,  1.70s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.87it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:11<00:08,  1.67s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.87it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:13<00:06,  1.65s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.85it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:15<00:04,  1.65s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.90it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:16<00:03,  1.64s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.86it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:18<00:01,  1.63s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.86it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.shufflenet_v2_x1_0(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.shufflenet_v2_x1_0')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1oe1jdze) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 151011<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf0ffdb4fb74d19a84846a690bfc50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.03MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113237-1oe1jdze/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113237-1oe1jdze/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>1e-05</td></tr><tr><td>val_loss</td><td>2.05658</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_runtime</td><td>28</td></tr><tr><td>_timestamp</td><td>1621663385</td></tr><tr><td>_step</td><td>35</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">models.shufflenet_v2_x1_0</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1oe1jdze\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1oe1jdze</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1oe1jdze). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.mobilenet_v3_large</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/5oz5vtdv\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/5oz5vtdv</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113306-5oz5vtdv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.67it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:01<00:19,  1.75s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.62it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.66it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:03<00:17,  1.77s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.77it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.77it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:05<00:15,  1.74s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.62it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:07<00:13,  1.75s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.74it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:08<00:12,  1.73s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.76it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:10<00:10,  1.73s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.78it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:12<00:08,  1.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.71it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:13<00:06,  1.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.75it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.75it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:15<00:05,  1.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.77it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:17<00:03,  1.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.77it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.74it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:18<00:01,  1.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.70it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.70it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v3_large(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mobilenet_v3_large')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5oz5vtdv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 151863<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eff0366aed84b6797f2e3fd30b793a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113306-5oz5vtdv/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113306-5oz5vtdv/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.01996</td></tr><tr><td>val_loss</td><td>1.17379</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_runtime</td><td>27</td></tr><tr><td>_timestamp</td><td>1621663428</td></tr><tr><td>_step</td><td>35</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>██▇▇▆▅▅▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁▂▂▁▂</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">models.mobilenet_v3_large</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/5oz5vtdv\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/5oz5vtdv</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:5oz5vtdv). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.mobilenet_v3_small</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3fzr2hdn\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3fzr2hdn</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113349-3fzr2hdn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.90it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.98it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:01<00:16,  1.53s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.02it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:03<00:15,  1.54s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.02it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.00it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:04<00:13,  1.52s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.02it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.99it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:06<00:12,  1.51s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:07<00:10,  1.50s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.04it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:09<00:08,  1.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.04it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:10<00:07,  1.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  2.00it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.02it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:11<00:05,  1.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:13<00:04,  1.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.04it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.04it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:14<00:02,  1.48s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.07it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.02it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.01it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:16<00:01,  1.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.05it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v3_small(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mobilenet_v3_small')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3fzr2hdn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 152306<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec95cb1b728409098cbadcfdd645ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.05MB of 0.05MB uploaded (0.03MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113349-3fzr2hdn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113349-3fzr2hdn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.02134</td></tr><tr><td>val_loss</td><td>1.21234</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_runtime</td><td>25</td></tr><tr><td>_timestamp</td><td>1621663459</td></tr><tr><td>_step</td><td>35</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>██▇▇▇▆▆▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▇▆▆▅▅▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">models.mobilenet_v3_small</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3fzr2hdn\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/3fzr2hdn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3fzr2hdn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.resnext50_32x4d</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2a3fc8a5\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2a3fc8a5</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113420-2a3fc8a5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.66it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.69it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:01<00:18,  1.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.72it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:03<00:16,  1.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.73it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:05<00:15,  1.68s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.71it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:06<00:13,  1.68s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.72it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.77it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:08<00:11,  1.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.64it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.65it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:10<00:10,  1.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.71it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:11<00:08,  1.70s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.72it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:13<00:06,  1.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.73it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.73it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:15<00:05,  1.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.72it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.71it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.82it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:16<00:03,  1.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.72it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.83it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:18<00:01,  1.68s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.73it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.72it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.resnext50_32x4d(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.resnext50_32x4d')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2a3fc8a5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 152887<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ff969bacc7418fbf62755d27cada6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113420-2a3fc8a5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113420-2a3fc8a5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.0</td></tr><tr><td>val_loss</td><td>24.87967</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_runtime</td><td>28</td></tr><tr><td>_timestamp</td><td>1621663504</td></tr><tr><td>_step</td><td>35</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">models.resnext50_32x4d</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2a3fc8a5\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2a3fc8a5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2a3fc8a5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.wide_resnet50_2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2kjv7wj2\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2kjv7wj2</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113504-2kjv7wj2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.12it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.14it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:02<00:27,  2.53s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:04<00:24,  2.48s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:07<00:22,  2.47s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:09<00:19,  2.47s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.18it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.16it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:12<00:17,  2.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.15it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.17it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:14<00:14,  2.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.19it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:17<00:12,  2.48s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.18it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:19<00:09,  2.47s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:22<00:07,  2.47s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.16it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.14it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.20it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:24<00:04,  2.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.18it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:27<00:02,  2.48s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.wide_resnet50_2(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.wide_resnet50_2')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2kjv7wj2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 153221<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ae37e0a6d54d1cbc3af4f9f7ff14fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.06MB of 0.06MB uploaded (0.04MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113504-2kjv7wj2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113504-2kjv7wj2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.0</td></tr><tr><td>val_loss</td><td>21.89334</td></tr><tr><td>accuracy</td><td>1.0</td></tr><tr><td>val_accuracy</td><td>1.0</td></tr><tr><td>_runtime</td><td>36</td></tr><tr><td>_timestamp</td><td>1621663545</td></tr><tr><td>_step</td><td>35</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">models.wide_resnet50_2</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2kjv7wj2\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/2kjv7wj2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2kjv7wj2). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">models.mnasnet1_0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1f8xey58\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Brands-Images-Clf/runs/1f8xey58</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/Car-Brands-Images-Clf/wandb/run-20210522_113546-1f8xey58</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A/home/indika/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.18it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.21it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.24it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:01<00:14,  1.35s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.24it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:02<00:13,  1.34s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.29it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.26it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.29it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:03<00:11,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.24it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.24it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.26it/s]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:05<00:10,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.21it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.16it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.21it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:06<00:09,  1.34s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.22it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.21it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.26it/s]\u001b[A\n",
      " 50%|█████     | 6/12 [00:08<00:08,  1.34s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.27it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:09<00:06,  1.34s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.27it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.28it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\u001b[A\n",
      " 67%|██████▋   | 8/12 [00:10<00:05,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.24it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\u001b[A\n",
      " 75%|███████▌  | 9/12 [00:12<00:03,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.27it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.26it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.26it/s]\u001b[A\n",
      " 83%|████████▎ | 10/12 [00:13<00:02,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.25it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.27it/s]\u001b[A\n",
      " 92%|█████████▏| 11/12 [00:14<00:01,  1.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  2.27it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.26it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "model = models.mnasnet1_0(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.mnasnet1_0')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1f8xey58) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 153887<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb0cb93bb97476e847e7ee38b0d1428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False, num_classes=50).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "wandb.init(project=PROJECT_NAME,name=f'models.resnet18')\n",
    "for _ in tqdm(range(EPOCHS),leave=False):\n",
    "    for i in tqdm(range(0,len(X_train),BATCH_SIZE),leave=False):\n",
    "        X_batch = X_train[i:i+BATCH_SIZE].view(-1,3,112,112).to(device)\n",
    "        y_batch = y_train[i:i+BATCH_SIZE].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        preds = preds.to(device)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        wandb.log({'loss':loss.item(),'val_loss':get_loss(criterion,y_test,model,X_test),'accuracy':test(model,X_train,y_train),'val_accuracy':test(model,X_test,y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
